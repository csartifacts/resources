# General Resources

## Process

* [https://www.artifact-eval.org/](https://www.artifact-eval.org/)
* [https://sysartifacts.github.io/](https://sysartifacts.github.io/): Systems Research Artifacts

## Advocacy
* [Artefact Review and Badging: Improving Confidence in our Experimental Results](https://acm-fca.org/2018/11/14/artefactreview/) by [Michel Steuwer](https://michel.steuwer.info/)
* [The Real Software Crisis: Repeatability as a Core Value](https://dl.acm.org/doi/10.1145/2658987) by [Shriram Krishnamurthi](https://cs.brown.edu/~sk/) and [Jan Vitek](http://janvitek.org/)

## Artifact Types

* [Proof Artifacts. Guidelines for Submission and Reviewing](https://proofartifacts.github.io/guidelines/) by [Marianna Rapoport](https://mrapoport.com/)
* [Checking machine-checked proofs](https://project.inria.fr/coqexchange/checking-machine-checked-proofs/)

## Hosting Platforms

* [Zenodo](https://zenodo.org/)
* [Nextjournal](https://nextjournal.com/)
* [Dagstuhl Artifacts Series (DARTS)](https://www.dagstuhl.de/publikationen/darts/)
* [figshare](https://figshare.com/)
* [Dryad](https://datadryad.org/stash)
* [Software Heritage Archive](https://archive.softwareheritage.org/)

## Packaging Platforms

* [Docker](https://www.docker.com/)
* [VirtualBox](https://www.virtualbox.org/)
* [Vagrant](https://www.vagrantup.com/)

## Experimentation and Evaluation

* [emulab](https://www.emulab.net/)

## Packaging Instructions

* [Making Your Code Citable](https://guides.github.com/activities/citable-code/): archiving GitHub repositories on Zenodo


## Badging

* [Artifact Review and Badging by ACM](https://www.acm.org/publications/policies/artifact-review-and-badging-current): A description of the badges and their requirements for ACM conferences

## Efforts
* [SIGSOFT Artifact Evaluation Working Group](https://github.com/acmsigsoft/artifact-evaluation)

# Artifact Preparation

* [Artifact Evaluation: Tips for Authors](https://blog.padhye.org/Artifact-Evaluation-Tips-for-Authors/) by [Rohan Padhye](https://rohan.padhye.org/): 10 actionable tips for preparing a successful artifact
* [HOWTO for AEC Submitters](https://docs.google.com/document/d/1pqzPtLVIvwLwJsZwCb2r7yzWMaifudHe1Xvn42T4CcA/edit) by [Dan Barowy](http://www.cs.williams.edu/~dbarowy/), [Charlie Curtsinger](https://curtsinger.cs.grinnell.edu/), [Emma Tosch](https://blog.emmatosch.com/bio.html), and [John Vilk](https://jvilk.com/)
* [Creating successful artifacts](https://hernanponcedeleon.github.io/articles/artifacts.html) by [Hernán Ponce de León](https://hernanponcedeleon.github.io/)
* [how to disclose data for double-blind review and make it archived open data upon acceptance](https://ineed.coffee/post/how-to-disclose-data-for-double-blind-review-and-make-it-archived-open-data-upon-acceptance.html) by [Daniel Graziotin](https://ineed.coffee/)
* [Generating an Artifact From a Benchmarking Setup as Part of CI](https://www.stefan-marr.de/2019/05/artifacts-from-ci/) by [Stefan Marr](https://www.stefan-marr.de/)

## Author Experience Reports
* [My first artifact: An author's perspective on the POPL'19 Artifact Evaluation process](http://www.simonjf.com/2018/12/14/popl19-aec.html) by [Simon Fowler](http://www.simonjf.com/)
* [How Are Award-winning Systems Research Artifacts Prepared](https://www.sigops.org/2021/how-are-award-winning-systems-research-artifacts-prepared-part-1/) by [Manuel Rigger](https://www.manuelrigger.at/): An interview on creating successful artifacts conducted by [Tianyin Xu](https://tianyin.github.io/) for the [ACM SIGOPS blog](https://www.sigops.org/blog/).

# Artifact Reviewing

## Reviewer Experience Reports

* [Experience with Artifact Evaluation for CAV 2015](https://dimjasevic.net/marko/2015/05/23/experience-with-artifact-evaluation/index.html) by [Marko Dimjašević](https://dimjasevic.net/marko/): Marko provides useful suggestions on improving the AE process as well as research artifacts based on his experience with the CAV AE process.
* [Why I will never join an Artifacts Evaluation Committee Again](https://inventitech.com/blog/why-i-will-never-review-artifacts-again/) by [Moritz Beller](https://inventitech.com/): Moritz describes his less ideal experience as a reviewer serving for the ESEC/FSE 2000 AE, and provides constructive criticism that is likely to serve future AE chairs.
* [My Experience of Artifact Evaluation in FPGA2020](https://j7cheng.wordpress.com/2020/07/08/my-experience-of-artifacts-evaluation-in-fpga2020/) by [Jianyi Cheng](https://j7cheng.wordpress.com/): Jianyi documents his experience as an author of an artifact as well as an AEC member of FPGA2020 and gives useful tips for future authors of artifacts.

# AE Chairing

## Chair Reports

* [Reflections on the VMCAI 2021 artifact evaluation](https://sigkill.dk/blog/2020-12-21-vmcai-artifact-evaluation.html) by [Troels Henriksen](https://sigkill.dk/)
* [OOPSLA 2020 Artifacts Chairs' Report](https://2020.splashcon.org/track/splash-2020-Artifacts#Chairs-Report) by [Colin Gordon](https://www.cs.drexel.edu/~csgordon/) and [Anders Møller](https://www.cs.au.dk/~amoeller/): a report featuring recommendations for future artifact evaluations

## Detailed Resources for Chairing an AE

* [How to survive an artifact evaluation with HotCRP](https://docs.google.com/document/d/1_Fq4mq5VJs-sMnBs39rTCEDWktb_qhcSeL3d9Kr4cD0/edit) by [Camil Demetrescu](http://www.dis.uniroma1.it/demetres/): slightly outdated, but still relevant instructions for using HotCRP in the AE process
* [ACM PPoPP’19 artifact evaluation report and HotCRP configuration](https://www.linkedin.com/pulse/acm-ppopp19-artifact-evaluation-report-hotcrp-grigori-fursin/) by [Grigori Fursin](http://fursin.net/research.html) and [Flavio Vella](https://www.unibz.it/en/faculties/computer-science/academic-staff/person/39806-flavio-vella): the detailed settings of the HotCRP instance configured for the PPoPP’19 AE and a short report on the process
* ["Artifact Evaluation Artifact" for OOPSLA'13](http://evaluate.inf.usi.ch/artifacts/aea) by [Steve Blackburn](https://users.cecs.anu.edu.au/~steveb/) and [Matthias Hauswirth](https://www.inf.usi.ch/faculty/hauswirth/): detailed description of the first OOPSLA AE process including the timeline, forms, and emails


# Systematic Studies and Papers

* [Community expectations for research artifacts and evaluation processes](https://dl.acm.org/doi/10.1145/3368089.3409767): A study of AE calls and an analysis of a reviewer survey to study the community expectations in PL/SE conferences
* [Getting Research Software to Work: A Case Study on Artifact Evaluation for OOPSLA 2019](http://lisanqd.com/wp-content/uploads/2019/11/accpub-OOPSLA2019-licensed.pdf) by [Erin Dahlgren](https://edahlgren.github.io/accpub/)
* [Evaluating the artifacts of SIGCOMM papers](https://dl.acm.org/doi/10.1145/3336937.3336944) by Damien Saucez, Luigi Iannone, and Olivier Bonaventure
* [Publish or perish, but do not forget your software artifacts](https://link.springer.com/article/10.1007/s10664-020-09851-6) by [Robert Heumüller](https://cse.cs.ovgu.de/cse/members/robert-heumueller/), [Sebastian Nielebock](https://cse.cs.ovgu.de/cse/members/sebastian-nielebock/), Jacob Krüger, and [Frank Ortmeier](https://cse.cs.ovgu.de/cse/members/frank-ortmeier/)

# Broader Reproducibility and Artifact Resources

* [cTuning](https://ctuning.org/ae/): many useful materials about reproducible science and [AE](https://ctuning.org/ae/).
* [Software Engineering Reproducibility Manifesto (SERM)](https://mboehme.github.io/manifesto) by [Marcel Böhme](https://mboehme.github.io/)
* [Artifact Evaluation for Reproducible Quantitative Research](https://www.sigarch.org/artifact-evaluation-for-reproducible-quantitative-research/)
* [SIGPLAN Empirical Evaluation Checklist](http://www.sigplan.org/Resources/EmpiricalEvaluation/)
